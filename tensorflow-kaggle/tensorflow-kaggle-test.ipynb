{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some globals, which are used across the remaining functions\n",
    "Image_width = 28\n",
    "Image_height = 28\n",
    "Image_Channels = 1\n",
    "IMAGE_SHAPE = (Image_width,Image_height,Image_Channels)\n",
    "NUM_CLASSES = 10\n",
    "# training parameters\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No Test labels so not using!! \n",
    "# train_df = pd.read_csv(\"../kaggleData/train.csv\")\n",
    "# test_df = pd.read_csv(\"../kaggleData/test.csv\")\n",
    "\n",
    "# y_train = train_df['label']\n",
    "# X_train = train_df.drop('label', axis=1)\n",
    "# X_test = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data  Cleaning and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../kaggleData/train.csv\")\n",
    "# test_df = pd.read_csv(\"../kaggleData/test.csv\")\n",
    "\n",
    "fullX = train_df.iloc[:, 1:].values # get all row for every other column\n",
    "fullY = train_df.iloc[:, :1].values # get every row for label\n",
    "length = fullX.shape[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(fullX, fullY, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(33600, 28, 28)\n",
    "X_test = X_test.reshape(8400, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full, validate_full = train_test_split(train_df, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f70fc20d00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 3332# may select anything up to 60,000\n",
    "plt.imshow(X_train[image_index], cmap='binary') # Show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 28, 28)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (X_train.astype('float32') / 255.0)\n",
    "X_test = (X_test.astype('float32') / 255.0)\n",
    "\n",
    "x_shape = X_train.shape\n",
    "x_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Simple TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Ott's Cats and dog model\n",
    "model = Sequential()\n",
    "\n",
    "# should feed in input shape [28,28]\n",
    "# only looking at image height and width\n",
    "\n",
    "model.add(Flatten(input_shape=[28,28]))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 573,104\n",
      "Trainable params: 573,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([], dtype=int64), array([2], dtype=int64),\n",
       "       array([], dtype=int64), ..., array([], dtype=int64),\n",
       "       array([9], dtype=int64), array([], dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_funky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 28, 28)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_funky.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_funky = X_train_funky.reshape(24000, 28, 28)\n",
    "X_test_funky = X_test_funky.reshape(6000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-186-b11988f97406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_funky\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_funky\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m--> 263\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "model.fit(X_train_funky, y_train_funky, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting our predicted Values with the digit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 5\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "predicted_val = []\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_test_funky[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        pred = model.predict_classes(X_test_funky[index:index+1])[0]\n",
    "        predicted_val.append(pred)\n",
    "        plt.title(\"Pred: {}\".format(pred))\n",
    "        plt.axis('off')\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  predicting the number and selecting the digit that is most probable \n",
    "prediction = model.predict(X_test)\n",
    "predictedValue = prediction.argmax(axis=1)\n",
    "\n",
    "# Comparing predicted digit to the actual digit value to determine the accuracy of the model\n",
    "accuracy = np.mean(y_test.ravel() == predictedValue.ravel())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from doing these tests\n",
    "\n",
    "EPOCHS = 30 \n",
    "\n",
    "model.add(Flatten(input_shape=[28,28])) # Change from 2-D to 1-D (28*28 neurons in input layer)\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "            \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "### accuracy^ 0.9792857142857143\n",
    "\n",
    "EPOCHS = 30 \n",
    "\n",
    "model.add(Flatten(input_shape=[28,28])) # Change from 2-D to 1-D (28*28 neurons in input layer)\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "            \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "### Accuracy ^ 0.9783333333333334\n",
    "\n",
    "EPOCHS = 30 \n",
    "\n",
    "model.add(Flatten(input_shape=[28,28])) # Change from 2-D to 1-D (28*28 neurons in input layer)\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "### Accuracy ^ 0.9763095238095238"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#potato = confusion_matrix(y_test, newVals)\n",
    "#potato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = model.predict_classes(X_test)\n",
    "#output_dict = {\"ImageId\": np.arange(1, len(preds) + 1, 1), \"label\": preds}\n",
    "#preds_df = pd.DataFrame(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.score(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# only looking at image height and width\n",
    "model.add(Flatten(input_shape=[28,28])) # Change from 2-D to 1-D (28*28 neurons in input layer)\n",
    "\n",
    "# Create Pyramid-like sequence for neural net\n",
    "model.add(Dense(300, activation=\"relu\"))\n",
    "model.add(Dense(200, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(10, activation='softmax')) # output activation should be softmax for classication > 2 output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:\n",
      " - X_train.shape = (33600, 28, 28), y_train.shape = (33600, 1)\n",
      " - X_test.shape = (8400, 28, 28)\n",
      "After preprocessing: \n",
      " - X_train.shape = (33600, 28, 28, 1), y_train.shape = (33600, 10)\n",
      " - X_test.shape = (8400, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print('Before preprocessing:')\n",
    "print(' - X_train.shape = {}, y_train.shape = {}'.format(X_train.shape, y_train.shape))\n",
    "print(' - X_test.shape = {}'.format(X_test.shape))\n",
    "\n",
    "# one-hot encode labels to 10 output classes corresponding to digits 0-9\n",
    "y_train = to_categorical(y_train, 10)\n",
    "\n",
    "# reshape the image arrays (make 2D arrays instead of 3D arrays)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "\n",
    "print('After preprocessing: ')\n",
    "print(' - X_train.shape = {}, y_train.shape = {}'.format(X_train.shape, y_train.shape))\n",
    "print(' - X_test.shape = {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 89,802\n",
      "Trainable params: 89,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(6), padding='same', activation='relu',\n",
    "                    input_shape=IMAGE_SHAPE)) # **** KEEP THIS TOO \n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(2), padding='same', activation='relu',\n",
    "                input_shape=IMAGE_SHAPE))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    ## Add desnse layers \n",
    "    model.add(Dense(32, activation = \n",
    "                    'relu'))\n",
    "    model.add(Dropout(0.45))\n",
    "    # output is softmax for 10 classes\n",
    "    model.add(Dense(10,activation = 'softmax')) # ****** NEED THIs STRIP TO THIS AND A INPUT LAYER \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2\n",
    "# go for small batch size then increase as we go... to prevent overfitting \n",
    "# need to know the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rot(alpha):\n",
    "    a = np.pi*alpha/180\n",
    "    R = np.array([[np.cos(a), -np.sin(a)],\n",
    "                 [np.sin(a), np.cos(a)]])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rotatedKK = mpimg.imread(\"../train_img/train_1.png\")\n",
    "imgplot = plt.imshow(rotatedKK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKING IMAGE FUNKYYYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [3],\n",
       "       [2],\n",
       "       ...,\n",
       "       [2],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNKY_SIZE = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-191-93de90589f4a>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_train_funky_np = np.array(y_train_funky)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([7], dtype=int64), array([2], dtype=int64),\n",
       "       array([1], dtype=int64), ..., array([], dtype=int64),\n",
       "       array([], dtype=int64), array([], dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "f = gzip.open('../fullDataset/t10k-labels-idx1-ubyte.gz','r')\n",
    "f.read(8)\n",
    "\n",
    "y_train_funky = []\n",
    "for i in range(0, FUNKY_SIZE):   \n",
    "    buf = f.read(1)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    y_train_funky.append(labels)\n",
    "\n",
    "# trying to change to numpy array\n",
    "y_train_funky_np = np.array(y_train_funky)\n",
    "y_train_funky_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_0.png',\n",
       " 'train_1.png',\n",
       " 'train_10.png',\n",
       " 'train_100.png',\n",
       " 'train_1000.png',\n",
       " 'train_10000.png',\n",
       " 'train_10001.png',\n",
       " 'train_10002.png',\n",
       " 'train_10003.png',\n",
       " 'train_10004.png',\n",
       " 'train_10005.png',\n",
       " 'train_10006.png',\n",
       " 'train_10007.png',\n",
       " 'train_10008.png',\n",
       " 'train_10009.png',\n",
       " 'train_1001.png',\n",
       " 'train_10010.png',\n",
       " 'train_10011.png',\n",
       " 'train_10012.png',\n",
       " 'train_10013.png',\n",
       " 'train_10014.png',\n",
       " 'train_10015.png',\n",
       " 'train_10016.png',\n",
       " 'train_10017.png',\n",
       " 'train_10018.png',\n",
       " 'train_10019.png',\n",
       " 'train_1002.png',\n",
       " 'train_10020.png',\n",
       " 'train_10021.png',\n",
       " 'train_10022.png',\n",
       " 'train_10023.png',\n",
       " 'train_10024.png',\n",
       " 'train_10025.png',\n",
       " 'train_10026.png',\n",
       " 'train_10027.png',\n",
       " 'train_10028.png',\n",
       " 'train_10029.png',\n",
       " 'train_1003.png',\n",
       " 'train_10030.png',\n",
       " 'train_10031.png',\n",
       " 'train_10032.png',\n",
       " 'train_10033.png',\n",
       " 'train_10034.png',\n",
       " 'train_10035.png',\n",
       " 'train_10036.png',\n",
       " 'train_10037.png',\n",
       " 'train_10038.png',\n",
       " 'train_10039.png',\n",
       " 'train_1004.png',\n",
       " 'train_10040.png',\n",
       " 'train_10041.png',\n",
       " 'train_10042.png',\n",
       " 'train_10043.png',\n",
       " 'train_10044.png',\n",
       " 'train_10045.png',\n",
       " 'train_10046.png',\n",
       " 'train_10047.png',\n",
       " 'train_10048.png',\n",
       " 'train_10049.png',\n",
       " 'train_1005.png',\n",
       " 'train_10050.png',\n",
       " 'train_10051.png',\n",
       " 'train_10052.png',\n",
       " 'train_10053.png',\n",
       " 'train_10054.png',\n",
       " 'train_10055.png',\n",
       " 'train_10056.png',\n",
       " 'train_10057.png',\n",
       " 'train_10058.png',\n",
       " 'train_10059.png',\n",
       " 'train_1006.png',\n",
       " 'train_10060.png',\n",
       " 'train_10061.png',\n",
       " 'train_10062.png',\n",
       " 'train_10063.png',\n",
       " 'train_10064.png',\n",
       " 'train_10065.png',\n",
       " 'train_10066.png',\n",
       " 'train_10067.png',\n",
       " 'train_10068.png',\n",
       " 'train_10069.png',\n",
       " 'train_1007.png',\n",
       " 'train_10070.png',\n",
       " 'train_10071.png',\n",
       " 'train_10072.png',\n",
       " 'train_10073.png',\n",
       " 'train_10074.png',\n",
       " 'train_10075.png',\n",
       " 'train_10076.png',\n",
       " 'train_10077.png',\n",
       " 'train_10078.png',\n",
       " 'train_10079.png',\n",
       " 'train_1008.png',\n",
       " 'train_10080.png',\n",
       " 'train_10081.png',\n",
       " 'train_10082.png',\n",
       " 'train_10083.png',\n",
       " 'train_10084.png',\n",
       " 'train_10085.png',\n",
       " 'train_10086.png',\n",
       " 'train_10087.png',\n",
       " 'train_10088.png',\n",
       " 'train_10089.png',\n",
       " 'train_1009.png',\n",
       " 'train_10090.png',\n",
       " 'train_10091.png',\n",
       " 'train_10092.png',\n",
       " 'train_10093.png',\n",
       " 'train_10094.png',\n",
       " 'train_10095.png',\n",
       " 'train_10096.png',\n",
       " 'train_10097.png',\n",
       " 'train_10098.png',\n",
       " 'train_10099.png',\n",
       " 'train_101.png',\n",
       " 'train_1010.png',\n",
       " 'train_10100.png',\n",
       " 'train_10101.png',\n",
       " 'train_10102.png',\n",
       " 'train_10103.png',\n",
       " 'train_10104.png',\n",
       " 'train_10105.png',\n",
       " 'train_10106.png',\n",
       " 'train_10107.png',\n",
       " 'train_10108.png',\n",
       " 'train_10109.png',\n",
       " 'train_1011.png',\n",
       " 'train_10110.png',\n",
       " 'train_10111.png',\n",
       " 'train_10112.png',\n",
       " 'train_10113.png',\n",
       " 'train_10114.png',\n",
       " 'train_10115.png',\n",
       " 'train_10116.png',\n",
       " 'train_10117.png',\n",
       " 'train_10118.png',\n",
       " 'train_10119.png',\n",
       " 'train_1012.png',\n",
       " 'train_10120.png',\n",
       " 'train_10121.png',\n",
       " 'train_10122.png',\n",
       " 'train_10123.png',\n",
       " 'train_10124.png',\n",
       " 'train_10125.png',\n",
       " 'train_10126.png',\n",
       " 'train_10127.png',\n",
       " 'train_10128.png',\n",
       " 'train_10129.png',\n",
       " 'train_1013.png',\n",
       " 'train_10130.png',\n",
       " 'train_10131.png',\n",
       " 'train_10132.png',\n",
       " 'train_10133.png',\n",
       " 'train_10134.png',\n",
       " 'train_10135.png',\n",
       " 'train_10136.png',\n",
       " 'train_10137.png',\n",
       " 'train_10138.png',\n",
       " 'train_10139.png',\n",
       " 'train_1014.png',\n",
       " 'train_10140.png',\n",
       " 'train_10141.png',\n",
       " 'train_10142.png',\n",
       " 'train_10143.png',\n",
       " 'train_10144.png',\n",
       " 'train_10145.png',\n",
       " 'train_10146.png',\n",
       " 'train_10147.png',\n",
       " 'train_10148.png',\n",
       " 'train_10149.png',\n",
       " 'train_1015.png',\n",
       " 'train_10150.png',\n",
       " 'train_10151.png',\n",
       " 'train_10152.png',\n",
       " 'train_10153.png',\n",
       " 'train_10154.png',\n",
       " 'train_10155.png',\n",
       " 'train_10156.png',\n",
       " 'train_10157.png',\n",
       " 'train_10158.png',\n",
       " 'train_10159.png',\n",
       " 'train_1016.png',\n",
       " 'train_10160.png',\n",
       " 'train_10161.png',\n",
       " 'train_10162.png',\n",
       " 'train_10163.png',\n",
       " 'train_10164.png',\n",
       " 'train_10165.png',\n",
       " 'train_10166.png',\n",
       " 'train_10167.png',\n",
       " 'train_10168.png',\n",
       " 'train_10169.png',\n",
       " 'train_1017.png',\n",
       " 'train_10170.png',\n",
       " 'train_10171.png',\n",
       " 'train_10172.png',\n",
       " 'train_10173.png',\n",
       " 'train_10174.png',\n",
       " 'train_10175.png',\n",
       " 'train_10176.png',\n",
       " 'train_10177.png',\n",
       " 'train_10178.png',\n",
       " 'train_10179.png',\n",
       " 'train_1018.png',\n",
       " 'train_10180.png',\n",
       " 'train_10181.png',\n",
       " 'train_10182.png',\n",
       " 'train_10183.png',\n",
       " 'train_10184.png',\n",
       " 'train_10185.png',\n",
       " 'train_10186.png',\n",
       " 'train_10187.png',\n",
       " 'train_10188.png',\n",
       " 'train_10189.png',\n",
       " 'train_1019.png',\n",
       " 'train_10190.png',\n",
       " 'train_10191.png',\n",
       " 'train_10192.png',\n",
       " 'train_10193.png',\n",
       " 'train_10194.png',\n",
       " 'train_10195.png',\n",
       " 'train_10196.png',\n",
       " 'train_10197.png',\n",
       " 'train_10198.png',\n",
       " 'train_10199.png',\n",
       " 'train_102.png',\n",
       " 'train_1020.png',\n",
       " 'train_10200.png',\n",
       " 'train_10201.png',\n",
       " 'train_10202.png',\n",
       " 'train_10203.png',\n",
       " 'train_10204.png',\n",
       " 'train_10205.png',\n",
       " 'train_10206.png',\n",
       " 'train_10207.png',\n",
       " 'train_10208.png',\n",
       " 'train_10209.png',\n",
       " 'train_1021.png',\n",
       " 'train_10210.png',\n",
       " 'train_10211.png',\n",
       " 'train_10212.png',\n",
       " 'train_10213.png',\n",
       " 'train_10214.png',\n",
       " 'train_10215.png',\n",
       " 'train_10216.png',\n",
       " 'train_10217.png',\n",
       " 'train_10218.png',\n",
       " 'train_10219.png',\n",
       " 'train_1022.png',\n",
       " 'train_10220.png',\n",
       " 'train_10221.png',\n",
       " 'train_10222.png',\n",
       " 'train_10223.png',\n",
       " 'train_10224.png',\n",
       " 'train_10225.png',\n",
       " 'train_10226.png',\n",
       " 'train_10227.png',\n",
       " 'train_10228.png',\n",
       " 'train_10229.png',\n",
       " 'train_1023.png',\n",
       " 'train_10230.png',\n",
       " 'train_10231.png',\n",
       " 'train_10232.png',\n",
       " 'train_10233.png',\n",
       " 'train_10234.png',\n",
       " 'train_10235.png',\n",
       " 'train_10236.png',\n",
       " 'train_10237.png',\n",
       " 'train_10238.png',\n",
       " 'train_10239.png',\n",
       " 'train_1024.png',\n",
       " 'train_10240.png',\n",
       " 'train_10241.png',\n",
       " 'train_10242.png',\n",
       " 'train_10243.png',\n",
       " 'train_10244.png',\n",
       " 'train_10245.png',\n",
       " 'train_10246.png',\n",
       " 'train_10247.png',\n",
       " 'train_10248.png',\n",
       " 'train_10249.png',\n",
       " 'train_1025.png',\n",
       " 'train_10250.png',\n",
       " 'train_10251.png',\n",
       " 'train_10252.png',\n",
       " 'train_10253.png',\n",
       " 'train_10254.png',\n",
       " 'train_10255.png',\n",
       " 'train_10256.png',\n",
       " 'train_10257.png',\n",
       " 'train_10258.png',\n",
       " 'train_10259.png',\n",
       " 'train_1026.png',\n",
       " 'train_10260.png',\n",
       " 'train_10261.png',\n",
       " 'train_10262.png',\n",
       " 'train_10263.png',\n",
       " 'train_10264.png',\n",
       " 'train_10265.png',\n",
       " 'train_10266.png',\n",
       " 'train_10267.png',\n",
       " 'train_10268.png',\n",
       " 'train_10269.png',\n",
       " 'train_1027.png',\n",
       " 'train_10270.png',\n",
       " 'train_10271.png',\n",
       " 'train_10272.png',\n",
       " 'train_10273.png',\n",
       " 'train_10274.png',\n",
       " 'train_10275.png',\n",
       " 'train_10276.png',\n",
       " 'train_10277.png',\n",
       " 'train_10278.png',\n",
       " 'train_10279.png',\n",
       " 'train_1028.png',\n",
       " 'train_10280.png',\n",
       " 'train_10281.png',\n",
       " 'train_10282.png',\n",
       " 'train_10283.png',\n",
       " 'train_10284.png',\n",
       " 'train_10285.png',\n",
       " 'train_10286.png',\n",
       " 'train_10287.png',\n",
       " 'train_10288.png',\n",
       " 'train_10289.png',\n",
       " 'train_1029.png',\n",
       " 'train_10290.png',\n",
       " 'train_10291.png',\n",
       " 'train_10292.png',\n",
       " 'train_10293.png',\n",
       " 'train_10294.png',\n",
       " 'train_10295.png',\n",
       " 'train_10296.png',\n",
       " 'train_10297.png',\n",
       " 'train_10298.png',\n",
       " 'train_10299.png',\n",
       " 'train_103.png',\n",
       " 'train_1030.png',\n",
       " 'train_10300.png',\n",
       " 'train_10301.png',\n",
       " 'train_10302.png',\n",
       " 'train_10303.png',\n",
       " 'train_10304.png',\n",
       " 'train_10305.png',\n",
       " 'train_10306.png',\n",
       " 'train_10307.png',\n",
       " 'train_10308.png',\n",
       " 'train_10309.png',\n",
       " 'train_1031.png',\n",
       " 'train_10310.png',\n",
       " 'train_10311.png',\n",
       " 'train_10312.png',\n",
       " 'train_10313.png',\n",
       " 'train_10314.png',\n",
       " 'train_10315.png',\n",
       " 'train_10316.png',\n",
       " 'train_10317.png',\n",
       " 'train_10318.png',\n",
       " 'train_10319.png',\n",
       " 'train_1032.png',\n",
       " 'train_10320.png',\n",
       " 'train_10321.png',\n",
       " 'train_10322.png',\n",
       " 'train_10323.png',\n",
       " 'train_10324.png',\n",
       " 'train_10325.png',\n",
       " 'train_10326.png',\n",
       " 'train_10327.png',\n",
       " 'train_10328.png',\n",
       " 'train_10329.png',\n",
       " 'train_1033.png',\n",
       " 'train_10330.png',\n",
       " 'train_10331.png',\n",
       " 'train_10332.png',\n",
       " 'train_10333.png',\n",
       " 'train_10334.png',\n",
       " 'train_10335.png',\n",
       " 'train_10336.png',\n",
       " 'train_10337.png',\n",
       " 'train_10338.png',\n",
       " 'train_10339.png',\n",
       " 'train_1034.png',\n",
       " 'train_10340.png',\n",
       " 'train_10341.png',\n",
       " 'train_10342.png',\n",
       " 'train_10343.png',\n",
       " 'train_10344.png',\n",
       " 'train_10345.png',\n",
       " 'train_10346.png',\n",
       " 'train_10347.png',\n",
       " 'train_10348.png',\n",
       " 'train_10349.png',\n",
       " 'train_1035.png',\n",
       " 'train_10350.png',\n",
       " 'train_10351.png',\n",
       " 'train_10352.png',\n",
       " 'train_10353.png',\n",
       " 'train_10354.png',\n",
       " 'train_10355.png',\n",
       " 'train_10356.png',\n",
       " 'train_10357.png',\n",
       " 'train_10358.png',\n",
       " 'train_10359.png',\n",
       " 'train_1036.png',\n",
       " 'train_10360.png',\n",
       " 'train_10361.png',\n",
       " 'train_10362.png',\n",
       " 'train_10363.png',\n",
       " 'train_10364.png',\n",
       " 'train_10365.png',\n",
       " 'train_10366.png',\n",
       " 'train_10367.png',\n",
       " 'train_10368.png',\n",
       " 'train_10369.png',\n",
       " 'train_1037.png',\n",
       " 'train_10370.png',\n",
       " 'train_10371.png',\n",
       " 'train_10372.png',\n",
       " 'train_10373.png',\n",
       " 'train_10374.png',\n",
       " 'train_10375.png',\n",
       " 'train_10376.png',\n",
       " 'train_10377.png',\n",
       " 'train_10378.png',\n",
       " 'train_10379.png',\n",
       " 'train_1038.png',\n",
       " 'train_10380.png',\n",
       " 'train_10381.png',\n",
       " 'train_10382.png',\n",
       " 'train_10383.png',\n",
       " 'train_10384.png',\n",
       " 'train_10385.png',\n",
       " 'train_10386.png',\n",
       " 'train_10387.png',\n",
       " 'train_10388.png',\n",
       " 'train_10389.png',\n",
       " 'train_1039.png',\n",
       " 'train_10390.png',\n",
       " 'train_10391.png',\n",
       " 'train_10392.png',\n",
       " 'train_10393.png',\n",
       " 'train_10394.png',\n",
       " 'train_10395.png',\n",
       " 'train_10396.png',\n",
       " 'train_10397.png',\n",
       " 'train_10398.png',\n",
       " 'train_10399.png',\n",
       " 'train_104.png',\n",
       " 'train_1040.png',\n",
       " 'train_10400.png',\n",
       " 'train_10401.png',\n",
       " 'train_10402.png',\n",
       " 'train_10403.png',\n",
       " 'train_10404.png',\n",
       " 'train_10405.png',\n",
       " 'train_10406.png',\n",
       " 'train_10407.png',\n",
       " 'train_10408.png',\n",
       " 'train_10409.png',\n",
       " 'train_1041.png',\n",
       " 'train_10410.png',\n",
       " 'train_10411.png',\n",
       " 'train_10412.png',\n",
       " 'train_10413.png',\n",
       " 'train_10414.png',\n",
       " 'train_10415.png',\n",
       " 'train_10416.png',\n",
       " 'train_10417.png',\n",
       " 'train_10418.png',\n",
       " 'train_10419.png',\n",
       " 'train_1042.png',\n",
       " 'train_10420.png',\n",
       " 'train_10421.png',\n",
       " 'train_10422.png',\n",
       " 'train_10423.png',\n",
       " 'train_10424.png',\n",
       " 'train_10425.png',\n",
       " 'train_10426.png',\n",
       " 'train_10427.png',\n",
       " 'train_10428.png',\n",
       " 'train_10429.png',\n",
       " 'train_1043.png',\n",
       " 'train_10430.png',\n",
       " 'train_10431.png',\n",
       " 'train_10432.png',\n",
       " 'train_10433.png',\n",
       " 'train_10434.png',\n",
       " 'train_10435.png',\n",
       " 'train_10436.png',\n",
       " 'train_10437.png',\n",
       " 'train_10438.png',\n",
       " 'train_10439.png',\n",
       " 'train_1044.png',\n",
       " 'train_10440.png',\n",
       " 'train_10441.png',\n",
       " 'train_10442.png',\n",
       " 'train_10443.png',\n",
       " 'train_10444.png',\n",
       " 'train_10445.png',\n",
       " 'train_10446.png',\n",
       " 'train_10447.png',\n",
       " 'train_10448.png',\n",
       " 'train_10449.png',\n",
       " 'train_1045.png',\n",
       " 'train_10450.png',\n",
       " 'train_10451.png',\n",
       " 'train_10452.png',\n",
       " 'train_10453.png',\n",
       " 'train_10454.png',\n",
       " 'train_10455.png',\n",
       " 'train_10456.png',\n",
       " 'train_10457.png',\n",
       " 'train_10458.png',\n",
       " 'train_10459.png',\n",
       " 'train_1046.png',\n",
       " 'train_10460.png',\n",
       " 'train_10461.png',\n",
       " 'train_10462.png',\n",
       " 'train_10463.png',\n",
       " 'train_10464.png',\n",
       " 'train_10465.png',\n",
       " 'train_10466.png',\n",
       " 'train_10467.png',\n",
       " 'train_10468.png',\n",
       " 'train_10469.png',\n",
       " 'train_1047.png',\n",
       " 'train_10470.png',\n",
       " 'train_10471.png',\n",
       " 'train_10472.png',\n",
       " 'train_10473.png',\n",
       " 'train_10474.png',\n",
       " 'train_10475.png',\n",
       " 'train_10476.png',\n",
       " 'train_10477.png',\n",
       " 'train_10478.png',\n",
       " 'train_10479.png',\n",
       " 'train_1048.png',\n",
       " 'train_10480.png',\n",
       " 'train_10481.png',\n",
       " 'train_10482.png',\n",
       " 'train_10483.png',\n",
       " 'train_10484.png',\n",
       " 'train_10485.png',\n",
       " 'train_10486.png',\n",
       " 'train_10487.png',\n",
       " 'train_10488.png',\n",
       " 'train_10489.png',\n",
       " 'train_1049.png',\n",
       " 'train_10490.png',\n",
       " 'train_10491.png',\n",
       " 'train_10492.png',\n",
       " 'train_10493.png',\n",
       " 'train_10494.png',\n",
       " 'train_10495.png',\n",
       " 'train_10496.png',\n",
       " 'train_10497.png',\n",
       " 'train_10498.png',\n",
       " 'train_10499.png',\n",
       " 'train_105.png',\n",
       " 'train_1050.png',\n",
       " 'train_10500.png',\n",
       " 'train_10501.png',\n",
       " 'train_10502.png',\n",
       " 'train_10503.png',\n",
       " 'train_10504.png',\n",
       " 'train_10505.png',\n",
       " 'train_10506.png',\n",
       " 'train_10507.png',\n",
       " 'train_10508.png',\n",
       " 'train_10509.png',\n",
       " 'train_1051.png',\n",
       " 'train_10510.png',\n",
       " 'train_10511.png',\n",
       " 'train_10512.png',\n",
       " 'train_10513.png',\n",
       " 'train_10514.png',\n",
       " 'train_10515.png',\n",
       " 'train_10516.png',\n",
       " 'train_10517.png',\n",
       " 'train_10518.png',\n",
       " 'train_10519.png',\n",
       " 'train_1052.png',\n",
       " 'train_10520.png',\n",
       " 'train_10521.png',\n",
       " 'train_10522.png',\n",
       " 'train_10523.png',\n",
       " 'train_10524.png',\n",
       " 'train_10525.png',\n",
       " 'train_10526.png',\n",
       " 'train_10527.png',\n",
       " 'train_10528.png',\n",
       " 'train_10529.png',\n",
       " 'train_1053.png',\n",
       " 'train_10530.png',\n",
       " 'train_10531.png',\n",
       " 'train_10532.png',\n",
       " 'train_10533.png',\n",
       " 'train_10534.png',\n",
       " 'train_10535.png',\n",
       " 'train_10536.png',\n",
       " 'train_10537.png',\n",
       " 'train_10538.png',\n",
       " 'train_10539.png',\n",
       " 'train_1054.png',\n",
       " 'train_10540.png',\n",
       " 'train_10541.png',\n",
       " 'train_10542.png',\n",
       " 'train_10543.png',\n",
       " 'train_10544.png',\n",
       " 'train_10545.png',\n",
       " 'train_10546.png',\n",
       " 'train_10547.png',\n",
       " 'train_10548.png',\n",
       " 'train_10549.png',\n",
       " 'train_1055.png',\n",
       " 'train_10550.png',\n",
       " 'train_10551.png',\n",
       " 'train_10552.png',\n",
       " 'train_10553.png',\n",
       " 'train_10554.png',\n",
       " 'train_10555.png',\n",
       " 'train_10556.png',\n",
       " 'train_10557.png',\n",
       " 'train_10558.png',\n",
       " 'train_10559.png',\n",
       " 'train_1056.png',\n",
       " 'train_10560.png',\n",
       " 'train_10561.png',\n",
       " 'train_10562.png',\n",
       " 'train_10563.png',\n",
       " 'train_10564.png',\n",
       " 'train_10565.png',\n",
       " 'train_10566.png',\n",
       " 'train_10567.png',\n",
       " 'train_10568.png',\n",
       " 'train_10569.png',\n",
       " 'train_1057.png',\n",
       " 'train_10570.png',\n",
       " 'train_10571.png',\n",
       " 'train_10572.png',\n",
       " 'train_10573.png',\n",
       " 'train_10574.png',\n",
       " 'train_10575.png',\n",
       " 'train_10576.png',\n",
       " 'train_10577.png',\n",
       " 'train_10578.png',\n",
       " 'train_10579.png',\n",
       " 'train_1058.png',\n",
       " 'train_10580.png',\n",
       " 'train_10581.png',\n",
       " 'train_10582.png',\n",
       " 'train_10583.png',\n",
       " 'train_10584.png',\n",
       " 'train_10585.png',\n",
       " 'train_10586.png',\n",
       " 'train_10587.png',\n",
       " 'train_10588.png',\n",
       " 'train_10589.png',\n",
       " 'train_1059.png',\n",
       " 'train_10590.png',\n",
       " 'train_10591.png',\n",
       " 'train_10592.png',\n",
       " 'train_10593.png',\n",
       " 'train_10594.png',\n",
       " 'train_10595.png',\n",
       " 'train_10596.png',\n",
       " 'train_10597.png',\n",
       " 'train_10598.png',\n",
       " 'train_10599.png',\n",
       " 'train_106.png',\n",
       " 'train_1060.png',\n",
       " 'train_10600.png',\n",
       " 'train_10601.png',\n",
       " 'train_10602.png',\n",
       " 'train_10603.png',\n",
       " 'train_10604.png',\n",
       " 'train_10605.png',\n",
       " 'train_10606.png',\n",
       " 'train_10607.png',\n",
       " 'train_10608.png',\n",
       " 'train_10609.png',\n",
       " 'train_1061.png',\n",
       " 'train_10610.png',\n",
       " 'train_10611.png',\n",
       " 'train_10612.png',\n",
       " 'train_10613.png',\n",
       " 'train_10614.png',\n",
       " 'train_10615.png',\n",
       " 'train_10616.png',\n",
       " 'train_10617.png',\n",
       " 'train_10618.png',\n",
       " 'train_10619.png',\n",
       " 'train_1062.png',\n",
       " 'train_10620.png',\n",
       " 'train_10621.png',\n",
       " 'train_10622.png',\n",
       " 'train_10623.png',\n",
       " 'train_10624.png',\n",
       " 'train_10625.png',\n",
       " 'train_10626.png',\n",
       " 'train_10627.png',\n",
       " 'train_10628.png',\n",
       " 'train_10629.png',\n",
       " 'train_1063.png',\n",
       " 'train_10630.png',\n",
       " 'train_10631.png',\n",
       " 'train_10632.png',\n",
       " 'train_10633.png',\n",
       " 'train_10634.png',\n",
       " 'train_10635.png',\n",
       " 'train_10636.png',\n",
       " 'train_10637.png',\n",
       " 'train_10638.png',\n",
       " 'train_10639.png',\n",
       " 'train_1064.png',\n",
       " 'train_10640.png',\n",
       " 'train_10641.png',\n",
       " 'train_10642.png',\n",
       " 'train_10643.png',\n",
       " 'train_10644.png',\n",
       " 'train_10645.png',\n",
       " 'train_10646.png',\n",
       " 'train_10647.png',\n",
       " 'train_10648.png',\n",
       " 'train_10649.png',\n",
       " 'train_1065.png',\n",
       " 'train_10650.png',\n",
       " 'train_10651.png',\n",
       " 'train_10652.png',\n",
       " 'train_10653.png',\n",
       " 'train_10654.png',\n",
       " 'train_10655.png',\n",
       " 'train_10656.png',\n",
       " 'train_10657.png',\n",
       " 'train_10658.png',\n",
       " 'train_10659.png',\n",
       " 'train_1066.png',\n",
       " 'train_10660.png',\n",
       " 'train_10661.png',\n",
       " 'train_10662.png',\n",
       " 'train_10663.png',\n",
       " 'train_10664.png',\n",
       " 'train_10665.png',\n",
       " 'train_10666.png',\n",
       " 'train_10667.png',\n",
       " 'train_10668.png',\n",
       " 'train_10669.png',\n",
       " 'train_1067.png',\n",
       " 'train_10670.png',\n",
       " 'train_10671.png',\n",
       " 'train_10672.png',\n",
       " 'train_10673.png',\n",
       " 'train_10674.png',\n",
       " 'train_10675.png',\n",
       " 'train_10676.png',\n",
       " 'train_10677.png',\n",
       " 'train_10678.png',\n",
       " 'train_10679.png',\n",
       " 'train_1068.png',\n",
       " 'train_10680.png',\n",
       " 'train_10681.png',\n",
       " 'train_10682.png',\n",
       " 'train_10683.png',\n",
       " 'train_10684.png',\n",
       " 'train_10685.png',\n",
       " 'train_10686.png',\n",
       " 'train_10687.png',\n",
       " 'train_10688.png',\n",
       " 'train_10689.png',\n",
       " 'train_1069.png',\n",
       " 'train_10690.png',\n",
       " 'train_10691.png',\n",
       " 'train_10692.png',\n",
       " 'train_10693.png',\n",
       " 'train_10694.png',\n",
       " 'train_10695.png',\n",
       " 'train_10696.png',\n",
       " 'train_10697.png',\n",
       " 'train_10698.png',\n",
       " 'train_10699.png',\n",
       " 'train_107.png',\n",
       " 'train_1070.png',\n",
       " 'train_10700.png',\n",
       " 'train_10701.png',\n",
       " 'train_10702.png',\n",
       " 'train_10703.png',\n",
       " 'train_10704.png',\n",
       " 'train_10705.png',\n",
       " 'train_10706.png',\n",
       " 'train_10707.png',\n",
       " 'train_10708.png',\n",
       " 'train_10709.png',\n",
       " 'train_1071.png',\n",
       " 'train_10710.png',\n",
       " 'train_10711.png',\n",
       " 'train_10712.png',\n",
       " 'train_10713.png',\n",
       " 'train_10714.png',\n",
       " 'train_10715.png',\n",
       " 'train_10716.png',\n",
       " 'train_10717.png',\n",
       " 'train_10718.png',\n",
       " 'train_10719.png',\n",
       " 'train_1072.png',\n",
       " 'train_10720.png',\n",
       " 'train_10721.png',\n",
       " 'train_10722.png',\n",
       " 'train_10723.png',\n",
       " 'train_10724.png',\n",
       " 'train_10725.png',\n",
       " 'train_10726.png',\n",
       " 'train_10727.png',\n",
       " 'train_10728.png',\n",
       " 'train_10729.png',\n",
       " 'train_1073.png',\n",
       " 'train_10730.png',\n",
       " 'train_10731.png',\n",
       " 'train_10732.png',\n",
       " 'train_10733.png',\n",
       " 'train_10734.png',\n",
       " 'train_10735.png',\n",
       " 'train_10736.png',\n",
       " 'train_10737.png',\n",
       " 'train_10738.png',\n",
       " 'train_10739.png',\n",
       " 'train_1074.png',\n",
       " 'train_10740.png',\n",
       " 'train_10741.png',\n",
       " 'train_10742.png',\n",
       " 'train_10743.png',\n",
       " 'train_10744.png',\n",
       " 'train_10745.png',\n",
       " 'train_10746.png',\n",
       " 'train_10747.png',\n",
       " 'train_10748.png',\n",
       " 'train_10749.png',\n",
       " 'train_1075.png',\n",
       " 'train_10750.png',\n",
       " 'train_10751.png',\n",
       " 'train_10752.png',\n",
       " 'train_10753.png',\n",
       " 'train_10754.png',\n",
       " 'train_10755.png',\n",
       " 'train_10756.png',\n",
       " 'train_10757.png',\n",
       " 'train_10758.png',\n",
       " 'train_10759.png',\n",
       " 'train_1076.png',\n",
       " 'train_10760.png',\n",
       " 'train_10761.png',\n",
       " 'train_10762.png',\n",
       " 'train_10763.png',\n",
       " 'train_10764.png',\n",
       " 'train_10765.png',\n",
       " 'train_10766.png',\n",
       " 'train_10767.png',\n",
       " 'train_10768.png',\n",
       " 'train_10769.png',\n",
       " 'train_1077.png',\n",
       " 'train_10770.png',\n",
       " 'train_10771.png',\n",
       " 'train_10772.png',\n",
       " 'train_10773.png',\n",
       " 'train_10774.png',\n",
       " 'train_10775.png',\n",
       " 'train_10776.png',\n",
       " 'train_10777.png',\n",
       " 'train_10778.png',\n",
       " 'train_10779.png',\n",
       " 'train_1078.png',\n",
       " 'train_10780.png',\n",
       " 'train_10781.png',\n",
       " 'train_10782.png',\n",
       " 'train_10783.png',\n",
       " 'train_10784.png',\n",
       " 'train_10785.png',\n",
       " 'train_10786.png',\n",
       " 'train_10787.png',\n",
       " 'train_10788.png',\n",
       " 'train_10789.png',\n",
       " 'train_1079.png',\n",
       " 'train_10790.png',\n",
       " 'train_10791.png',\n",
       " 'train_10792.png',\n",
       " 'train_10793.png',\n",
       " 'train_10794.png',\n",
       " 'train_10795.png',\n",
       " 'train_10796.png',\n",
       " 'train_10797.png',\n",
       " 'train_10798.png',\n",
       " 'train_10799.png',\n",
       " 'train_108.png',\n",
       " 'train_1080.png',\n",
       " 'train_10800.png',\n",
       " 'train_10801.png',\n",
       " 'train_10802.png',\n",
       " 'train_10803.png',\n",
       " 'train_10804.png',\n",
       " 'train_10805.png',\n",
       " 'train_10806.png',\n",
       " 'train_10807.png',\n",
       " 'train_10808.png',\n",
       " 'train_10809.png',\n",
       " 'train_1081.png',\n",
       " 'train_10810.png',\n",
       " 'train_10811.png',\n",
       " 'train_10812.png',\n",
       " 'train_10813.png',\n",
       " 'train_10814.png',\n",
       " 'train_10815.png',\n",
       " 'train_10816.png',\n",
       " 'train_10817.png',\n",
       " 'train_10818.png',\n",
       " 'train_10819.png',\n",
       " 'train_1082.png',\n",
       " 'train_10820.png',\n",
       " 'train_10821.png',\n",
       " 'train_10822.png',\n",
       " 'train_10823.png',\n",
       " 'train_10824.png',\n",
       " 'train_10825.png',\n",
       " 'train_10826.png',\n",
       " 'train_10827.png',\n",
       " 'train_10828.png',\n",
       " 'train_10829.png',\n",
       " 'train_1083.png',\n",
       " 'train_10830.png',\n",
       " 'train_10831.png',\n",
       " 'train_10832.png',\n",
       " 'train_10833.png',\n",
       " 'train_10834.png',\n",
       " 'train_10835.png',\n",
       " 'train_10836.png',\n",
       " 'train_10837.png',\n",
       " 'train_10838.png',\n",
       " 'train_10839.png',\n",
       " 'train_1084.png',\n",
       " 'train_10840.png',\n",
       " 'train_10841.png',\n",
       " 'train_10842.png',\n",
       " 'train_10843.png',\n",
       " 'train_10844.png',\n",
       " 'train_10845.png',\n",
       " 'train_10846.png',\n",
       " 'train_10847.png',\n",
       " 'train_10848.png',\n",
       " 'train_10849.png',\n",
       " 'train_1085.png',\n",
       " 'train_10850.png',\n",
       " 'train_10851.png',\n",
       " 'train_10852.png',\n",
       " 'train_10853.png',\n",
       " 'train_10854.png',\n",
       " 'train_10855.png',\n",
       " 'train_10856.png',\n",
       " 'train_10857.png',\n",
       " 'train_10858.png',\n",
       " 'train_10859.png',\n",
       " 'train_1086.png',\n",
       " 'train_10860.png',\n",
       " 'train_10861.png',\n",
       " 'train_10862.png',\n",
       " 'train_10863.png',\n",
       " 'train_10864.png',\n",
       " 'train_10865.png',\n",
       " 'train_10866.png',\n",
       " 'train_10867.png',\n",
       " 'train_10868.png',\n",
       " 'train_10869.png',\n",
       " 'train_1087.png',\n",
       " 'train_10870.png',\n",
       " 'train_10871.png',\n",
       " 'train_10872.png',\n",
       " 'train_10873.png',\n",
       " 'train_10874.png',\n",
       " 'train_10875.png',\n",
       " 'train_10876.png',\n",
       " 'train_10877.png',\n",
       " 'train_10878.png',\n",
       " 'train_10879.png',\n",
       " 'train_1088.png',\n",
       " 'train_10880.png',\n",
       " 'train_10881.png',\n",
       " 'train_10882.png',\n",
       " 'train_10883.png',\n",
       " 'train_10884.png',\n",
       " 'train_10885.png',\n",
       " 'train_10886.png',\n",
       " 'train_10887.png',\n",
       " 'train_10888.png',\n",
       " 'train_10889.png',\n",
       " 'train_1089.png',\n",
       " 'train_10890.png',\n",
       " 'train_10891.png',\n",
       " 'train_10892.png',\n",
       " 'train_10893.png',\n",
       " 'train_10894.png',\n",
       " 'train_10895.png',\n",
       " 'train_10896.png',\n",
       " 'train_10897.png',\n",
       " ...]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names = os.listdir(\"./../train_img\")[:FUNKY_SIZE]\n",
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 28, 28)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_big = []\n",
    "for img in image_names:\n",
    "    # convert image to 1 color channel \n",
    "    colorImage = Image.open(\"./../train_img/\" + img).convert('1')\n",
    "    image_sequence = colorImage.getdata()\n",
    "    image_array = np.array(image_sequence).reshape(28,28)\n",
    "    \n",
    "#     degrees = random.randint(1,360)\n",
    "#     rptated = colorImage.rotate(degrees)\n",
    "    \n",
    "    # switching to float \n",
    "    float_array = image_array.astype(float)\n",
    "    X_train_big.append(float_array)\n",
    "\n",
    "# changing to numpy array\n",
    "X_train_funky = np.array(X_train_big)\n",
    "X_train_funky.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-193-f653a4c742ff>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(y_train_funky)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([7], dtype=int64), array([2], dtype=int64),\n",
       "       array([1], dtype=int64), ..., array([], dtype=int64),\n",
       "       array([], dtype=int64), array([], dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train_funky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_funky, X_test_funky, y_train_funky, y_test_funky = train_test_split(X_train_funky, y_train_funky, test_size = 0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colorImage = Image.open(\"./../train_img/train_1.png\").convert('1')\n",
    "image_sequence = colorImage.getdata()\n",
    "image_array = np.array(image_sequence).reshape(28,28)\n",
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [5],\n",
       "       [2],\n",
       "       ...,\n",
       "       [8],\n",
       "       [8],\n",
       "       [8]], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 28, 28, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = colorImage.rotate(22)\n",
    "rotated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Corey\\\\Desktop\\\\info371-adhoc\\\\tensorflow-kaggle'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(1,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-8733536ebd59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdegrees\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mrptated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolorImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mrptated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, title, command)\u001b[0m\n\u001b[0;32m   2224\u001b[0m             )\n\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2226\u001b[1;33m         \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3189\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3190\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"_internal_pillow\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3191\u001b[1;33m     \u001b[0m_showxv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m_showxv\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m   3203\u001b[0m             \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m         )\n\u001b[1;32m-> 3205\u001b[1;33m     \u001b[0mImageShow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \"\"\"\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mviewer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_viewers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# hook methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;34m\"\"\"Display the given image.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow_file\u001b[1;34m(self, file, **options)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;34m\"\"\"Display the given file.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run this to rotate\n",
    "for img in image_names:\n",
    "    colorImage = Image.open(\"./../train_img/\" + img).convert('1')\n",
    "    degrees = random.randint(1,360)\n",
    "    rptated = colorImage.rotate(degrees)\n",
    "    rptated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6,\n",
       "       6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2,\n",
       "       3, 5, 1, 2, 4, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelList = train_labels[0:50]\n",
    "len(labelList)\n",
    "labelListN = np.array(labelList).astype(int)\n",
    "labelListN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>train_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>train_1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>train_10.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>train_11.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train_12.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>train_13.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>train_14.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>train_15.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>train_16.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>train_17.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>train_18.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>train_19.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>train_2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>train_20.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>train_21.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>train_22.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>train_23.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>train_24.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>train_25.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>train_26.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>train_27.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>train_28.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>train_29.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>train_3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>train_30.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>train_31.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>train_32.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>train_33.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>train_34.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>train_35.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>train_36.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>train_37.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>train_38.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>train_39.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>train_4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>train_40.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>train_41.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>train_42.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>train_43.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>train_44.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>train_45.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7</td>\n",
       "      <td>train_46.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>train_47.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>train_48.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>train_49.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>train_5.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>train_6.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>train_7.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>train_8.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>train_9.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id          name\n",
       "0    7   train_0.png\n",
       "1    2   train_1.png\n",
       "2    1  train_10.png\n",
       "3    0  train_11.png\n",
       "4    4  train_12.png\n",
       "5    1  train_13.png\n",
       "6    4  train_14.png\n",
       "7    9  train_15.png\n",
       "8    5  train_16.png\n",
       "9    9  train_17.png\n",
       "10   0  train_18.png\n",
       "11   6  train_19.png\n",
       "12   9   train_2.png\n",
       "13   0  train_20.png\n",
       "14   1  train_21.png\n",
       "15   5  train_22.png\n",
       "16   9  train_23.png\n",
       "17   7  train_24.png\n",
       "18   3  train_25.png\n",
       "19   4  train_26.png\n",
       "20   9  train_27.png\n",
       "21   6  train_28.png\n",
       "22   6  train_29.png\n",
       "23   5   train_3.png\n",
       "24   4  train_30.png\n",
       "25   0  train_31.png\n",
       "26   7  train_32.png\n",
       "27   4  train_33.png\n",
       "28   0  train_34.png\n",
       "29   1  train_35.png\n",
       "30   3  train_36.png\n",
       "31   1  train_37.png\n",
       "32   3  train_38.png\n",
       "33   4  train_39.png\n",
       "34   7   train_4.png\n",
       "35   2  train_40.png\n",
       "36   7  train_41.png\n",
       "37   1  train_42.png\n",
       "38   2  train_43.png\n",
       "39   1  train_44.png\n",
       "40   1  train_45.png\n",
       "41   7  train_46.png\n",
       "42   4  train_47.png\n",
       "43   2  train_48.png\n",
       "44   3  train_49.png\n",
       "45   5   train_5.png\n",
       "46   1   train_6.png\n",
       "47   2   train_7.png\n",
       "48   4   train_8.png\n",
       "49   4   train_9.png"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_label_df = pd.DataFrame({\"id\": labelList, \"name\": image_names})\n",
    "img_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If class_mode=\"categorical\", y_col=\"id\" column values must be type string, list or tuple.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-50391a3662bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# y-col is target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m train_generator = train_datagen.flow_from_dataframe(dataframe=img_label_df, \n\u001b[0m\u001b[0;32m     25\u001b[0m                                             \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../train_img\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                         \u001b[0mx_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m           DeprecationWarning)\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m     return DataFrameIterator(\n\u001b[0m\u001b[0;32m   1082\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m       validate_filenames=True):\n\u001b[1;32m--> 556\u001b[1;33m     super(DataFrameIterator, self).__init__(\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m# check that inputs match the required class_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_filenames\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# check which image files are valid and keep them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter_valid_filepaths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m                 raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n\u001b[0m\u001b[0;32m    215\u001b[0m                                 \u001b[1;34m'values must be type string, list or tuple.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                                 .format(self.class_mode, y_col))\n",
      "\u001b[1;31mTypeError\u001b[0m: If class_mode=\"categorical\", y_col=\"id\" column values must be type string, list or tuple."
     ]
    }
   ],
   "source": [
    "    ## Training and validation data generator:\n",
    "    # https://www.tensorflow.org/tutorials/load_data/numpy flow from tensor slices\n",
    "\n",
    "    # following this for flow from dataframe https://vijayabhaskar96.medium.com/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import os\n",
    "\n",
    "\n",
    "# This is from cats and dogs \n",
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "\n",
    "# dataframe is all image names\n",
    "# directory is pulled from here... \n",
    "# x-col is file name\n",
    "# y-col is target \n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=img_label_df, \n",
    "                                                directory=\"../train_img\", \n",
    "                                            x_col=\"name\", y_col=\"id\", \n",
    "                                                    class_mode=\"categorical\", \n",
    "                                            target_size=(28,28), \n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    batch_size=32)\n",
    "\n",
    "train_generator\n",
    "    \n",
    "# loop over images and distort everything in a little bit of random way. \n",
    "# Linear algebra stuff!! \n",
    "# shifting by adding vector \n",
    "# zoom out: multiply by ([1.1,0], [0,1.1])\n",
    "# Share \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tensorflow distort data on load \n",
    "history = model.fit(train_generator, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_test[index].mean(axis=2), cmap=\"binary\", interpolation=\"nearest\")\n",
    "        pred = model.predict_classes(X_test[index:index+1])[0]\n",
    "        plt.title(\"Pred: {}\".format(pred))\n",
    "        plt.axis('off')\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  predicting the number and selecting the digit that is most probable \n",
    "prediction = model.predict(X_test)\n",
    "predictedValue = prediction.argmax(axis=1)\n",
    "\n",
    "# Comparing predicted digit to the actual digit value to determine the accuracy of the model\n",
    "accuracy = np.mean(y_test.ravel() == predictedValue.ravel())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with Convolution\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu',\n",
    "                    input_shape=IMAGE_SHAPE))\n",
    "                    \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu',\n",
    "            input_shape=IMAGE_SHAPE))\n",
    "            \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.45)) #output is softmax for 10 classes\n",
    "\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "### 0.9864285714285714\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu',\n",
    "                    input_shape=IMAGE_SHAPE))\n",
    "                    \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu',\n",
    "            input_shape=IMAGE_SHAPE))\n",
    "            \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.45)) #output is softmax for 10 classes\n",
    "\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "### 0.9878571428571429\n",
    "\n",
    "NUM_EPOCHS = 20 batchsize= NA \n",
    "\n",
    "K.clear_session()\n",
    "    \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu',input_shape=IMAGE_SHAPE))\n",
    "                \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu',\n",
    "            input_shape=IMAGE_SHAPE))\n",
    "            \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.45))\n",
    "\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "## 0.9921428571428571"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using new Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('number3.png')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray_image,cmap='Greys')\n",
    "plt.show()\n",
    "gray_image.dtype\n",
    "\n",
    "# https://pythonprogramming.altervista.org/split-square-images-into-many-images-with-python-and-image_slicer/?doing_wp_cron=1620172948.7784969806671142578125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "image = color.rgb2gray(image)\n",
    "\n",
    "image_rescaled = rescale(image, 0.25, anti_aliasing=False)\n",
    "image_resized = resize(image, (28, 28,1),\n",
    "                       anti_aliasing=True)\n",
    "\n",
    "#print(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_resized, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_resized_model = resize(image, (1, 28, 28,1),\n",
    "                       anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(image_resized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes from the Ott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives you 0 and positive values tenso\n",
    "# fast and simple weights/outputs \n",
    "\n",
    "# normalizes the coefficients so the weights \n",
    "# behaves more stably especially during fitting. \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# drops out 50% of the batch nodes randomly \n",
    "# forces the model to be less perfect. Avoid overfitting \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# returns valid probabilities\n",
    "# softmax good for categorical variables\n",
    "# gives you valid probabilities \n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
